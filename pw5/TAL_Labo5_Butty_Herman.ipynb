{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b5b976-960e-4bba-a831-d8351cd796d6",
   "metadata": {},
   "source": [
    "# Cours TAL - Laboratoire 5<br/>Le modèle word2vec et ses applications \n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Le but de ce travail est de comparer un modèle word2vec pré-entraîné avec deux modèles que vous entraînerez vous-mêmes sur des jeux de tailles différentes.  La comparaison se fera sur une tâche de similarité de mots et sur une tâche de raisonnement par analogie, les deux en anglais.  Vous utiliserez la librairie Python Gensim qui offre des fonctions pour manipuler des vecteurs de mots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "541f3288-695c-4874-9088-37ded86c6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import downloader as api\n",
    "import scipy\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48dece8-fffb-44e3-9baa-3c8b3ed8515c",
   "metadata": {},
   "source": [
    "## Tester en évaluer un modèle déjà entrainé sur Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3126cb3-62f4-415c-881d-4ca648f2d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger le modèle pour la première fois\n",
    "#w2v_vectors = api.load(\"word2vec-google-news-300\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04819b3c-5375-489d-85c2-9c50bb03be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer le modèle\n",
    "path_to_file = \"C:\\\\Users\\\\Vicky\\\\gensim-data\\\\word2vec-google-news-300\\\\word2vec-google-news-300.gz\"\n",
    "w2v_vectors = KeyedVectors.load_word2vec_format(path_to_file, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d96219-4064-45fe-bc8d-aaa76a78df3e",
   "metadata": {},
   "source": [
    "a. Quelle place en mémoire occupe le processus du notebook avec les vecteurs de mots ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b9a1aa-53c3-4d98-98c8-7162cd537d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation mémoire : 3.90 GB\n"
     ]
    }
   ],
   "source": [
    "process = psutil.Process(os.getpid())\n",
    "memory_usage = process.memory_info().rss / (1024 * 1024 * 1024)  # En GB\n",
    "\n",
    "print(f\"Utilisation mémoire : {memory_usage:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b93fee-4a27-4c13-95a2-10204e45d9e8",
   "metadata": {},
   "source": [
    "b. Quelle est la dimension de l’espace vectoriel dans lequel les mots sont représentés ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67d535d-78d9-4861-ba3d-80b17b8712c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de l'espace vectoriel : 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimension de l'espace vectoriel : {w2v_vectors.vector_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c34296-7593-480a-8f10-65a79eeb1292",
   "metadata": {},
   "source": [
    "c. Quelle est la taille du vocabulaire connu du modèle ?  Veuillez afficher cinq mots anglais qui sont dans le vocabulaire et deux qui ne le sont pas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5cc59d2-a4e8-45cb-9d07-070f503c3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 3000000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille du vocabulaire : {len(w2v_vectors.key_to_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41fbc829-dacc-4f7b-a8f1-f7902a09ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer : Mot présent\n",
      "apple : Mot présent\n",
      "cat : Mot présent\n",
      "gibberish : Mot présent\n",
      "music : Mot présent\n",
      "ulotrichous : Mot absent\n",
      "tittynope : Mot absent\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    # Mot présents dans le vocabulaire\n",
    "    'computer', \n",
    "    'apple', \n",
    "    'cat', \n",
    "    'gibberish', \n",
    "    'music', \n",
    "\n",
    "    # Mots absents du vocabulaire\n",
    "    'ulotrichous', # Adj. 1. Having wooly hair (https://en.wiktionary.org/wiki/ulotrichous)\n",
    "    'tittynope' # Noun 1. A small amount left over; a modicum. (https://en.wiktionary.org/wiki/tittynope)\n",
    "]\n",
    "\n",
    "for word in words:\n",
    "    print(f'{word} : {'Mot présent' if word in w2v_vectors.key_to_index else 'Mot absent'}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb28094-7519-4e00-89b7-f8fa59d4d517",
   "metadata": {},
   "source": [
    "> Lors de nos tests, nous avons observé que plusieurs mots pensé comme potentiellement absents étaient en réalité connu par le modèle. Les mots inconnus sont donc à chercher dans des domaines spécialisés ou des mots désuets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125ab92-050b-40fc-ac6e-4a3b7e87dfb5",
   "metadata": {},
   "source": [
    "d. Quelle est la similarité entre les mots rabbit et carrot ?  Veuillez rappeler comment on mesure les similarités entre deux mots grâce à leurs vecteurs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c794ade-0588-49ea-804f-ffb3fa25e85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similarité entre 'rabbit' et 'carrot' est de 0.363\n"
     ]
    }
   ],
   "source": [
    "w1 = \"rabbit\"\n",
    "w2 = \"carrot\"\n",
    "print(f\"La similarité entre '{w1}' et '{w2}' est de {w2v_vectors.similarity(w1, w2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065dfb92-29f5-4886-bb62-7094958c922c",
   "metadata": {},
   "source": [
    "> La similarité est mesurée à l'aide de la distance cosinus entre les deux vecteurs, calculée avec la formule\n",
    "> sim_cos\n",
    "> $$\n",
    "sim_{cosine}(a, b) = \\frac{a \\cdot b}{||a|| \\cdot ||b||}\n",
    "$$\n",
    "> _Rappel : $a \\cdot b$ est le produit scalaire entre les deux vecteurs. $||a||$ et $||b||$ sont leurs normes._\n",
    ">\n",
    "> Les valeurs de similarité varient donc entre -1 et 1. Un similarité de 1 signifie que les vecteurs sont identiques alors qu'une valeur de -1 indique qu'ils sont opposés. Une valeur de 0 indique que les vecteurs sont orthogonaux et donc que les mots sont sans rapport l'un avec l'autre.\n",
    "> Dans notre cas, `rabbit` et `carrot` ont une similarité de 0.363, indiquant une certaine proximité dans l'espace vectoriel mais sans que ceux-ci soient réellement proche et interchangeables dans un phrase, comme pourraient l'être `rabbit` avec d'autres animaux (fox, possum, cat, squirrel, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e258c9-2b0a-43c4-b762-e850a91a04a6",
   "metadata": {},
   "source": [
    "e. Considérez au moins 5 paires de mots anglais, certains proches par leurs sens, d’autres plus éloignés.  Pour chaque paire, calculez la similarité entre les deux mots.  Veuillez indiquer si les similarités obtenues correspondent à vos intuitions sur la proximité des sens des mots.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c7e14e-15a0-4018-8cd8-1f6ea93914bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similarité entre 'sleepy' et 'somnolent' est de 0.597\n",
      "La similarité entre 'kitten' et 'cat' est de 0.746\n",
      "La similarité entre 'blue' et 'teal' est de 0.636\n",
      "La similarité entre 'win' et 'lose' est de 0.395\n",
      "La similarité entre 'light' et 'dark' est de 0.471\n",
      "La similarité entre 'early' et 'late' est de 0.812\n",
      "La similarité entre 'book' et 'car' est de 0.128\n",
      "La similarité entre 'William' et 'sea' est de -0.077\n",
      "La similarité entre 'jewelry' et 'hunger' est de -0.000\n",
      "La similarité entre 'ray' et 'skate' est de 0.104\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    # Words with similar senses => Should be a relatively high similarity\n",
    "    [\"sleepy\", \"somnolent\"],\n",
    "    [\"kitten\", \"cat\"],\n",
    "    [\"blue\", \"teal\"],\n",
    "\n",
    "    # Words with opposit senses, but that can be uses in same context => Should be around 0.3 - 0.5\n",
    "    [\"win\", \"lose\"],\n",
    "    [\"light\", \"dark\"],\n",
    "    [\"early\", \"late\"],\n",
    "\n",
    "    # Words with different senses, that cannot be used in same context => Should be a relatively low similarity\n",
    "    [\"book\", \"car\"],\n",
    "    [\"William\", \"sea\"],\n",
    "    [\"jewelry\", \"hunger\"],\n",
    "    \n",
    "    # Other (Can be ambiguous words) => Will probably be a small similarity\n",
    "    [\"ray\", \"skate\"] # Those are two cartilaginous fishes\n",
    "]\n",
    "\n",
    "for pair in words:\n",
    "    print(f\"La similarité entre '{pair[0]}' et '{pair[1]}' est de {w2v_vectors.similarity(pair[0], pair[1]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3758a53-0961-40f3-a609-4bffa58f63bf",
   "metadata": {},
   "source": [
    "> Parmis les paires considérées, les similarités correspondent assez bien avec nos intuitions, à l'exception du cas de `early` et `late`, qui sera discuté au point suivant.\n",
    "> \n",
    "> Globalement, les mots de sens proche sont proches dans l'espace vectoriel et les mots de sens éloignés ont des similarités proche de 0. Malgré nos efforts pour trouver des paires de mots avec de grandes valeurs négatives, nous n'avons pas réussis à en trouver. Les mots les plus éloignés restent avec des valeurs négatives très faibles et sont difficile à trouver. Il est également intéressant de voir que des mots ayants plusieurs sens, comme c'est le cas pour `ray` et `skate` qui sont les noms de poissons catilagineux, sont utilisés dans le sens le plus courant et peuvent donc offrir des résultats surprenants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b330668-4979-4d35-959c-25a6424bfe81",
   "metadata": {},
   "source": [
    "f. Pouvez-vous trouver des mots de sens opposés mais qui sont proches selon le modèle ?  \n",
    "Comment expliquez-vous cela ?  Est-ce une qualité ou un défaut du modèle word2vec ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5c8824-a71e-42b8-a336-359818d08832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similarité entre 'blue' et 'red' est de 0.723\n",
      "La similarité entre 'early' et 'late' est de 0.812\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    [\"blue\", \"red\"],\n",
    "    [\"early\", \"late\"]\n",
    "]\n",
    "\n",
    "for pair in words:\n",
    "    print(f\"La similarité entre '{pair[0]}' et '{pair[1]}' est de {w2v_vectors.similarity(pair[0], pair[1]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f8702-55ea-4460-a1c1-f4742cf76102",
   "metadata": {},
   "source": [
    "> La question précédente nous avait permis de trouver la paire `early`-`late`, qui possède une similarité beaucoup plus élevée que ce à quoi l'on pourrait s'attendre. Bien que ces deux mots soient des antonymes, ils peuvent être utilisés dans des contextes très similaires. Après quelques recherches, nous avons également trouvé la paire `blue`-`red`, avec un score de similarité plus élevé qu'attendu.\n",
    ">\n",
    "> Word2Vec apprends des représentations vectorielles en se basant sur les contextes d'apparition des mots et non pas sur leur sens, il est donc normal que les paires comme `early`-`late` ou  `blue`-`red` possède des vecteurs similaires. Cet méthode d'apprentissage des vecteurs de mots permet au modèle de bien capter la manière dont une langue est utilisée (mots liés par leur utilisation) et permet de comprendre des similarités (analogie ou opposition) entre des mots. Si l'on cherche à avoir une distinction au niveau du sens (synonymes vs anthonymes), Word2Vec n'est pas assez précis et il faudra se tourner vers d'autres modèles, plus performants dans cette tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce450f3e-e1c9-4da0-8814-439aadbec4ee",
   "metadata": {},
   "source": [
    "g. En vous aidant de la [documentation de Gensim sur KeyedVectors](https://radimrehurek.com/gensim_3.8.3/models/keyedvectors.html), obtenez les scores du modèle word2vec sur les données de test WordSimilarity-353.  Veuillez rappeler en 1-2 phrases comment les différents scores sont calculés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6626e7d-f085-40e7-979c-59a822bd66b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson: 0.6239 (p-value: 1.7963e-39)\n",
      "Corrélation de Spearman: 0.6589 (p-value: 2.5346e-45)\n",
      "Ratio OOV: 0.0\n"
     ]
    }
   ],
   "source": [
    "eval_wordsim = w2v_vectors.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "\n",
    "print(f\"Corrélation de Pearson: {eval_wordsim[0][0]:.4f} (p-value: {eval_wordsim[0][1]:.4e})\")\n",
    "print(f\"Corrélation de Spearman: {eval_wordsim[1][0]:.4f} (p-value: {eval_wordsim[1][1]:.4e})\")\n",
    "print(f\"Ratio OOV: {eval_wordsim[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffab6e-b863-4da1-8bc6-248411bc5340",
   "metadata": {},
   "source": [
    "> La méthode `evaluate_word_pairs()` compare la similarité cosinus entre les vecteurs de mots du modèle avec les scores de similarité humaine fournis dans le fichier wordsim353.tsv. Les scores retournées sont la corrélation de Pearson (Valeur entre -1 et 1 indiquant la corrélation linéaires entre les similarités prédites et attendues), la corrélation de Spearman (mesure la corrélation de rang, c'est à dire de l'ordre relatif des similarités) et le ratio OOV (indique la proportion de paires de mots contenant au moins un mot hors vocabulaire (Out-Of-Vocabulary))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3469b9-cfa0-4c91-9fb6-39cac32583e4",
   "metadata": {},
   "source": [
    "h. En vous aidant de la documentation, calculez le score du modèle word2vec sur les données questions-words.txt. Attention, cette évaluation prend une dizaine de minutes, donc il vaut mieux commencer par tester avec un fragment de ce fichier (copier/coller les 100 premières analogies).  Expliquez en 1-2 phrases comment ce score est calculé et ce qu’il mesure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524690cc-102c-460e-a483-04ce52310f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7401448525607863\n"
     ]
    }
   ],
   "source": [
    "eval_qw = w2v_vectors.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {eval_qw[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2707c-071d-4185-b9a4-2d111583eaab",
   "metadata": {},
   "source": [
    "> La méthode `evaluate_word_analogies()` mesure la performance du modèle sur des tâches d'analogie de mots, où il doit trouver un mot D qui complète l'analogie \"A est à B comme C est à D\". Le score obtenu correspond à la proportion de bonnes réponses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c93b43-aea5-4378-89fe-ba42c427e6b7",
   "metadata": {},
   "source": [
    "## 2. Entraîner deux nouveaux modèles word2vec à partir de deux corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b5c7fe-2427-4ee0-bbc1-82b68e776df3",
   "metadata": {},
   "source": [
    "a. En utilisant gensim.downloader (voir question 1) récupérez le corpus qui contient les 108 premiers caractères de Wikipédia (en anglais) avec la commande : `corpus = api.load('text8')`. Combien de phrases et de mots (tokens) possède ce corpus ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7124b9f1-79c1-47e8-8e2e-a0c17ea0a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases dans le corpus : 1701\n",
      "Nombre de mots (tokens) dans le corpus : 17005207\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load(\"text8\")\n",
    "\n",
    "print(f\"Nombre de phrases dans le corpus : {api.info('text8')['num_records']}\")\n",
    "print(f\"Nombre de mots (tokens) dans le corpus : {sum(len(sentence) for sentence in corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e202f2-c1b8-4f9e-b849-fb8cc43b26a4",
   "metadata": {},
   "source": [
    "b. Entraînez un nouveau modèle word2vec sur ce nouveau corpus (voir la [documentation de Word2vec](https://radimrehurek.com/gensim/models/word2vec.html)).  Si nécessaire, procédez progressivement, en commençant par utiliser 1% du corpus, puis 10%, etc., pour contrôler le temps nécessaire.    \n",
    "• Veuillez indiquer la dimension choisie pour le embedding de ce nouveau modèle.  \n",
    "• Combien de temps prend l’entraînement sur le corpus total ?   \n",
    "• Quelle est la taille (en Mo) du modèle word2vec résultant ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb80719-fe1d-442a-a532-ac2c68cee66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 24s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t8_model = Word2Vec(sentences=corpus, vector_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4dcdf-b04c-4633-b32d-f8e1a4cfef2c",
   "metadata": {},
   "source": [
    "> L'entrainement de ce modèle a donc pris 1min 8s, avec un temps total cumulé passé par tous les coeurs du processeur de 3 min 24s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb76fbd-7ff5-4f76-b597-a8aa0f442d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension des embeddings : 300\n",
      "Taille du modèle sauvegardé : 2.08 Mo\n"
     ]
    }
   ],
   "source": [
    "t8_model.save(\"word2vec_text8.model\")\n",
    "\n",
    "model_size = os.path.getsize(\"word2vec_text8.model\") / (1024 * 1024)  # Mo\n",
    "\n",
    "print(f\"Dimension des embeddings : {t8_model.vector_size}\")\n",
    "print(f\"Taille du modèle sauvegardé : {model_size:.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b87af-690d-4f94-8ca4-cd030a0bcf38",
   "metadata": {},
   "source": [
    "c. Mesurez la qualité de ce modèle comme en (1g) et (1h).  Ce modèle est-il meilleur que celui entraîné sur Google News ?  Quelle est selon vous la raison de la différence ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9572f6-83ea-4035-8ab2-516458a8752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson: 0.6095 (p-value: 4.4018e-37)\n",
      "Corrélation de Spearman: 0.6271 (p-value: 9.2635e-40)\n",
      "Ratio OOV: 0.56657223796034\n"
     ]
    }
   ],
   "source": [
    "eval_wordsim = t8_model.wv.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "\n",
    "print(f\"Corrélation de Pearson: {eval_wordsim[0][0]:.4f} (p-value: {eval_wordsim[0][1]:.4e})\")\n",
    "print(f\"Corrélation de Spearman: {eval_wordsim[1][0]:.4f} (p-value: {eval_wordsim[1][1]:.4e})\")\n",
    "print(f\"Ratio OOV: {eval_wordsim[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f704eed9-daff-4cd2-bcc3-ebbbc86c5f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.2598866887305772\n"
     ]
    }
   ],
   "source": [
    "eval_qw = t8_model.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {eval_qw[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f2b56-2443-40f3-ae4d-f1b843c12253",
   "metadata": {},
   "source": [
    "> Le modèle entrainé sur le corpus Text8 est globalement moins performant que celui entrainé sur Google News. Bien que les scores de similarités soient légèrement plus faibles sur notre modèle, les p-values associées sont beaucoup plus grandes. Le modèle possède également un score beaucoup plus faible sur le test d'analogie, entre autre, dû au fait que beaucoup de termes ne sont pas connus.\n",
    ">\n",
    "> La taille du corpus Google News étant beaucoup plus grande (~40x) que celle de Text8, il est normal que le modèle Google News soit plus performant que le modèle Text8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230ede61-94e7-404f-83fe-d4b1432b6a18",
   "metadata": {},
   "source": [
    "d. Téléchargez maintenant le corpus quatre fois plus grand constitué de la concaténation du corpus text8 et des dépêches économiques de Reuters [fourni par l’enseignant et appelé wikipedia_augmented.zip](https://drive.switch.ch/index.php/s/iYI9yB0PpL7iUFS) (à décompresser en un fichier ‘.dat’ de 413 Mo). Entraînez un nouveau modèle word2vec sur ce corpus, en précisant la dimension choisie pour les embeddings.   \n",
    "\n",
    "• Utilisez la classe `Text8Corpus()` pour charger ce corpus, ce qui fera automatiquement la tokenisation et la segmentation en phrases.    \n",
    "• Combien de temps prend l’entraînement ?    \n",
    "• Quelle est la taille (en Mo) du modèle word2vec résultant ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca88e130-1b0b-4d07-ab1b-2f21f2f64954",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_augmented = Text8Corpus('data/wikipedia_augmented.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aca9460-3682-469a-bd61-ca8a35a27839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14min 58s\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t8_extended_model = Word2Vec(sentences=corpus_augmented, vector_size=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f658b-f4fe-4567-ae0c-5bc62568e65c",
   "metadata": {},
   "source": [
    "> L'entrainement de ce modèle a donc pris 5min 1s, avec un temps total cumulé passé par tous les coeurs du processeur de 14min 58s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43ba9280-0042-42fe-90dd-69b4b687eac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension des embeddings : 300\n",
      "Taille du modèle sauvegardé : 3.71 Mo\n"
     ]
    }
   ],
   "source": [
    "t8_extended_model.save(\"word2vec_text8_extended.model\")\n",
    "\n",
    "model_size = os.path.getsize(\"word2vec_text8_extended.model\") / (1024 * 1024)  # Mo\n",
    "\n",
    "print(f\"Dimension des embeddings : {t8_model.vector_size}\")\n",
    "print(f\"Taille du modèle sauvegardé : {model_size:.2f} Mo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a699340-60d9-487b-8112-3257174f2821",
   "metadata": {},
   "source": [
    "e. Testez ce modèle comme en (1g) et (1h).  Est-il meilleur que le précédent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad861477-4aab-4a04-b6ea-e890acd6d759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélation de Pearson: 0.5112 (p-value: 6.6893e-25)\n",
      "Corrélation de Spearman: 0.5230 (p-value: 3.5533e-26)\n",
      "Ratio OOV: 0.0\n"
     ]
    }
   ],
   "source": [
    "eval_wordsim = t8_extended_model.wv.evaluate_word_pairs(datapath(\"wordsim353.tsv\"))\n",
    "\n",
    "print(f\"Corrélation de Pearson: {eval_wordsim[0][0]:.4f} (p-value: {eval_wordsim[0][1]:.4e})\")\n",
    "print(f\"Corrélation de Spearman: {eval_wordsim[1][0]:.4f} (p-value: {eval_wordsim[1][1]:.4e})\")\n",
    "print(f\"Ratio OOV: {eval_wordsim[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8827283e-01a1-457e-8698-5964663447f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3531107243854688\n"
     ]
    }
   ],
   "source": [
    "eval_qw = t8_extended_model.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
    "print(f\"Score: {eval_qw[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3ecc3-c7ca-4ea4-9f8a-26b593d31f2b",
   "metadata": {},
   "source": [
    "> Le modèle avec le corpus Text8 augmenté est meilleur sur le test d'analogie que le modèle Text8, mais reste beaucoup moins bon que le modèle Google News. L'impact de l'augmentation du nombre de tokens est facilement visible grâce au ratio OOV: tout les mots du test d'analogie sont connus, contrairement pour le modèle Text8 de base. Les scores de similarités sont moins bons que ceux obtenus par le modèle Text8, avec des p-values bien plus grandes également, ce qui indique une corrélation moins forte entre les vecteurs de mots.\n",
    ">\n",
    "> Le corpus utilisé pour ce modèle est une version étendue du coprus Text8, enrichi avec les dépêches écononiques de Reuters. Le corpus possède donc beaucoup plus de tokens et réussis à couvrir l'ensemble des mots utilisés dans le test d'analogie. Les vecteurs de mots résultants sont donc influencés par cet ajout et sont donc différents de ceux obtenus avec le corpus Text8 de base, entrainant une différence dans les scores de similarité. Le volume et le contexte des données d'entrainement influencent donc grandement les performances du modèle avec les tests de Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb8249-7c35-4885-b602-3c4f24e89310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TAL",
   "language": "python",
   "name": "tal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
