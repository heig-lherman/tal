{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\"/>\n",
    "\n",
    "# Cours TAL - Laboratoire 6\n",
    "# Trois méthodes de désambiguïsation lexicale\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "L'objectif de ce laboratoire est d'implémenter et de comparer plusieurs méthodes de désambiguïsation lexicale (en anglais, *Word Sense Disambiguation* ou WSD).  Vous utiliserez un corpus avec plusieurs milliers de phrases, chaque phrase contenant une occurrence du mot anglais *interest* annotée avec le sens que ce mot possède dans la phrase respective.  Les trois méthodes sont les suivantes (elles seront détaillées par la suite) :\n",
    "\n",
    "* Algorithme de Lesk simplifié.\n",
    "* Utilisation de word2vec.\n",
    "* Classification supervisée utilisant des traits lexicaux.\n",
    "\n",
    "Les deux premières méthodes n'utilisent pas l'apprentissage automatique.  Elles fonctionnent selon le même principe : comparer le contexte d'une occurrence de *interest* avec chacune des définitions des sens (*synsets*) et choisir la définition la plus proche du contexte.  L'algorithme de Lesk définit la proximité comme le nombre de mots en commun, alors que word2vec la calcule comme la similarité de vecteurs.  La dernière méthode vise à classifier les occurrences de *interest*, les sens étant les classes, et les attributs étant les mots du contexte (apprentissage supervisé)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:25.489517Z",
     "start_time": "2025-05-22T12:28:24.317219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from random import randrange, shuffle\n",
    "from math import floor, ceil"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analyse des données\n",
    "\n",
    "Téléchargez le corpus *interest* depuis le [site du Prof. Ted Pedersen](http://www.d.umn.edu/~tpederse/data.html) (il se trouve en bas de sa page web).  Téléchargez l'archive ZIP marquée *original format without POS tags* et extrayez le fichier `interest-original.txt`.  Téléchargez également le fichier `README.int.txt` indiqué à la ligne au-dessus. Veuillez répondre brièvement aux questions suivantes :\n",
    "\n",
    "a. Quelles sont les URL du fichier ZIP et celle du fichier `README.int.txt` ?\n",
    "\n",
    "b. Quel est le format du fichier `interest-original.txt` et comment sont annotés les sens de *interest* ?\n",
    "\n",
    "c. Est-ce qu'il y a aussi des occurrences au pluriel (*interests*) à traite ?\n",
    "\n",
    "d. Comment sont annotées les phrases qui contiennent plusieurs occurrences du mot *interest* ?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> a.\n",
    ">    - Archive du corpus: https://www.d.umn.edu/~tpederse/Data/interest-original.nopos.tar.gz\n",
    ">    - Fichier README: https://www.d.umn.edu/~tpederse/Data/README.int.txt\n",
    ">\n",
    "> b. Les phrases sont séparées par lignes intercalées par des séparateurs `$$`, chaque phrase contient au moins une occurrence du mot *interest* annoté par un numéro de sens (1 à 6) précédé d'un underscore (e.g. `interest_6` indiquant \"money paid for the use of money\"). Les tokens, incluant la ponctuation, sont séparés par des espaces. Si un segment filtré d'une phrase n'est pas immédiatement adjacent au segment précédent ou suivant dans le corpus original, ils sont intercalés par un séparateur `===...`.\n",
    ">\n",
    "> c. Oui, les occurrence du mot au pluriel sont marquées telles quelles et annotées de la même manière (e.g. `interests_4`).\n",
    ">\n",
    "> d. Si une phrase contient plusieurs occurrence du mot *interest*, elles sont dupliquées avec une seule occurrence du mot taggée à la fois, l'autre étant préfixée d'un astérisque (e.g. `*interest`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1e.** D'après le fichier `README.int.txt`, quelles sont les définitions des six sens de *interest* annotés dans les données et quelles sont leurs fréquences ? Vous pouvez copier/coller l'extrait de `README`ici."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 1.  361 occurrences (15%) - readiness to give attention\n",
    "> 2.   11 occurrences (01%) - quality of causing attention to be given to\n",
    "> 3.   66 occurrences (03%) - activity, etc. that one gives attention to\n",
    "> 4.  178 occurrences (08%) - advantage, advancement or favor\n",
    "> 5.  500 occurrences (21%) - a share in a company or business\n",
    "> 6. 1252 occurrences (53%) - money paid for the use of money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1f.** De quel dictionnaire viennent les sens précédents ? Où peut-on le consulter en ligne ?  Veuillez aligner les définitions du dictionnaire avec les six sens annotés en écrivant par exemple `Sense 3 = \"an activity that you enjoy doing or a subject that you enjoy studying\"`."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> La version électronique de la première édition du [Longman's Dictionary of Contemporary English](https://www.ldoceonline.com/). La version utilisée pour les annotations n'est plus consultable. La version actuelle (la sixième édition) définit les 6 sens comme suit:\n",
    ">\n",
    "> 1. Sense 1 = \"if you have an interest in something or someone, you want to know or learn more about them\"\n",
    "> 2. Sense 2 = \"a quality or feature of something that attracts your attention or makes you want to know more about it\"\n",
    "> 3. Sense 3 = \"an activity that you enjoy doing or a subject that you enjoy studying\"\n",
    "> 4. Sense 4 = \"the things that bring advantages to someone or something\"\n",
    "> 5. Sense 5 = \"if you have an interest in a particular company or industry, you own shares in it\"\n",
    "> 6. Sense 6 = \"the extra money that you must pay back when you borrow money\", \"money paid to you by a bank or financial institution when you keep money in an account there\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1g.** En consultant [WordNet en ligne](http://wordnetweb.princeton.edu/perl/webwn), trouvez les définitions des synsets  pour le **nom commun** *interest*.  Combien de synsets y a-t-il ?  Veuillez indiquer comme avant la **définition** de chaque synset pour chacun des six sens ci-dessus (au besoin, fusionner ou ignorer des synsets)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:25.506923Z",
     "start_time": "2025-05-22T12:28:25.503815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instructs NLTK to load the local WordNet 3.1 database, since the online version does not exist anymore.\n",
    "from os import path\n",
    "\n",
    "nltk.data.path.append(path.abspath(path.join(path.curdir, 'nltk_data')))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.260222Z",
     "start_time": "2025-05-22T12:28:25.635087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "print(f\"WordNet version: {wn.get_version()}\")\n",
    "\n",
    "sn = wn.synsets('interest', pos=wn.NOUN)\n",
    "print(f\"Il y a {len(sn)} synsets pour le nom commun 'interest'\")\n",
    "\n",
    "df = pd.DataFrame(columns=['Synset', 'POS', 'Definition', 'Lemmas', 'Examples'])\n",
    "for i, s in enumerate(sorted(sn, key=lambda x: x.name())):\n",
    "  df.loc[i + 1] = [s.name(), s.pos(), s.definition(), ', '.join(s.lemma_names()), '; '.join(s.examples())]\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordNet version: 3.1\n",
      "Il y a 7 synsets pour le nom commun 'interest'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          Synset POS                                         Definition  \\\n",
       "1  interest.n.01   n  a sense of concern with and curiosity about so...   \n",
       "2  interest.n.03   n  the power of attracting or holding one's atten...   \n",
       "3  interest.n.04   n  a fixed charge for borrowing money; usually a ...   \n",
       "4  interest.n.05   n  (law) a right or legal share of something; a f...   \n",
       "5  interest.n.06   n  (usually plural) a social group whose members ...   \n",
       "6   pastime.n.01   n  a diversion that occupies one's time and thoug...   \n",
       "7      sake.n.01   n                a reason for wanting something done   \n",
       "\n",
       "                       Lemmas  \\\n",
       "1       interest, involvement   \n",
       "2   interest, interestingness   \n",
       "3                    interest   \n",
       "4             interest, stake   \n",
       "5    interest, interest_group   \n",
       "6  pastime, interest, pursuit   \n",
       "7              sake, interest   \n",
       "\n",
       "                                            Examples  \n",
       "1                               an interest in music  \n",
       "2  they said nothing of great interest; primary c...  \n",
       "3     how much interest do you pay on your mortgage?  \n",
       "4  they have interests all over the world; a stak...  \n",
       "5           the iron interests stepped up production  \n",
       "6  sailing is her favorite pastime; his main past...  \n",
       "7  for your sake; died for the sake of his countr...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset</th>\n",
       "      <th>POS</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>Examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>interest.n.01</td>\n",
       "      <td>n</td>\n",
       "      <td>a sense of concern with and curiosity about so...</td>\n",
       "      <td>interest, involvement</td>\n",
       "      <td>an interest in music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>interest.n.03</td>\n",
       "      <td>n</td>\n",
       "      <td>the power of attracting or holding one's atten...</td>\n",
       "      <td>interest, interestingness</td>\n",
       "      <td>they said nothing of great interest; primary c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interest.n.04</td>\n",
       "      <td>n</td>\n",
       "      <td>a fixed charge for borrowing money; usually a ...</td>\n",
       "      <td>interest</td>\n",
       "      <td>how much interest do you pay on your mortgage?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interest.n.05</td>\n",
       "      <td>n</td>\n",
       "      <td>(law) a right or legal share of something; a f...</td>\n",
       "      <td>interest, stake</td>\n",
       "      <td>they have interests all over the world; a stak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interest.n.06</td>\n",
       "      <td>n</td>\n",
       "      <td>(usually plural) a social group whose members ...</td>\n",
       "      <td>interest, interest_group</td>\n",
       "      <td>the iron interests stepped up production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pastime.n.01</td>\n",
       "      <td>n</td>\n",
       "      <td>a diversion that occupies one's time and thoug...</td>\n",
       "      <td>pastime, interest, pursuit</td>\n",
       "      <td>sailing is her favorite pastime; his main past...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sake.n.01</td>\n",
       "      <td>n</td>\n",
       "      <td>a reason for wanting something done</td>\n",
       "      <td>sake, interest</td>\n",
       "      <td>for your sake; died for the sake of his countr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 1. Sense 1 = Synset(interest.n.01) = \"a sense of concern with and curiosity about someone or something\"\n",
    "> 2. Sense 2 = Synset(interest.n.03) = \"the power of attracting or holding one's attention (because it is unusual or exciting etc.)\"\n",
    "> 3. Sense 3 = Synset(pastime.n.01) = \"a diversion that occupies one's time and thoughts (usually pleasantly)\"\n",
    "> 4. Sense 4 = Synset(sake.n.01) = \"a reason for wanting something done\"\n",
    "> 5. Sense 5 = Synset(interest.n.05) = \"(law) a right or legal share of something; a financial involvement with something\"\n",
    "> 6. Sense 6 = Synset(interest.n.04) = \"a fixed charge for borrowing money; usually a percentage of the amount borrowed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1h.** Définissez (manuellement, ou avec quelques lignes de code) une liste nommée `senses1` avec les mots des définitions du README, en supprimant les stopwords (p.ex. les mots < 4 lettres).  Affichez la liste."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.328747Z",
     "start_time": "2025-05-22T12:28:27.325618Z"
    }
   },
   "source": [
    "senses1 = [\n",
    "  [\"readiness\", \"give\", \"attention\"],\n",
    "  [\"quality\", \"causing\", \"attention\"],\n",
    "  [\"activity\", \"attention\"],\n",
    "  [\"advantage\", \"advancement\", \"favor\"],\n",
    "  [\"share\", \"company\", \"business\"],\n",
    "  [\"money\", \"paid\"],\n",
    "]\n",
    "\n",
    "print(senses1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['readiness', 'give', 'attention'], ['quality', 'causing', 'attention'], ['activity', 'attention'], ['advantage', 'advancement', 'favor'], ['share', 'company', 'business'], ['money', 'paid']]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**1i.** En combinant les définitions obtenues aux points (4) et (5) ci-dessus, construisez une liste nommée `senses2` avec pour chacun des sens de *interest* une liste de **mots-clés** correspondants.  Vous pouvez concaténer les définitions, puis écrire des instructions en Python pour extraire les mots (uniques).  Respectez l'ordre des sens données par `README`, et à la fin affichez `senses2`."
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.434289Z",
     "start_time": "2025-05-22T12:28:27.429897Z"
    }
   },
   "source": [
    "senses_ldoce = [\n",
    "  [\"interest\"],\n",
    "  [\"quality\", \"feature\", \"attracts\", \"attention\"],\n",
    "  [\"activity\", \"enjoy\", \"doing\", \"subject\", \"enjoy\", \"studying\"],\n",
    "  [\"things\", \"bring\", \"advantages\"],\n",
    "  [\"interest\", \"particular\", \"company\", \"industry\"],\n",
    "  [\"extra\", \"money\", \"pay\", \"back\"],\n",
    "]\n",
    "\n",
    "senses_wordnet = [\n",
    "  [\"sense\", \"concern\", \"curiosity\"],\n",
    "  [\"power\", \"attracting\", \"holding\", \"attention\", \"unusual\", \"exciting\"],\n",
    "  [\"diversion\", \"occupies\", \"time\", \"thoughts\", \"pleasantly\"],\n",
    "  [\"reason\", \"wanting\"],\n",
    "  [\"right\", \"legal\", \"share\", \"financial\", \"involvement\"],\n",
    "  [\"fixed\", \"charge\", \"borrowing\", \"money\", \"percentage\", \"amount\", \"borrowed\"],\n",
    "]\n",
    "\n",
    "senses2 = [\n",
    "  list(set(senses_ldoce[i] + senses_wordnet[i]))\n",
    "  for i in range(len(senses_ldoce))\n",
    "]\n",
    "\n",
    "print(senses2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['curiosity', 'sense', 'concern', 'interest'], ['attention', 'exciting', 'feature', 'attracts', 'unusual', 'power', 'holding', 'quality', 'attracting'], ['subject', 'doing', 'occupies', 'diversion', 'enjoy', 'studying', 'activity', 'thoughts', 'time', 'pleasantly'], ['things', 'bring', 'wanting', 'advantages', 'reason'], ['right', 'industry', 'legal', 'company', 'share', 'involvement', 'financial', 'interest', 'particular'], ['borrowed', 'charge', 'amount', 'fixed', 'money', 'extra', 'borrowing', 'pay', 'back', 'percentage']]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1j.** Chargez les données depuis `interest-original.txt` dans une liste appelée `sentences` qui contient pour chaque phrase la liste des mots (sans les séparateurs *$$* et *===...*).  Ces phrases sont-elles déjà tokenisées en mots ?  Sinon, faites-le.  À ce stade, ne modifiez pas encore les occurrences annotées *interest(s)\\_X*.  Comptez le nombre total de phrases et affichez-en trois au hasard."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.654433Z",
     "start_time": "2025-05-22T12:28:27.570484Z"
    }
   },
   "source": [
    "# Veuillez répondre ici à la question.\n",
    "sentences = []\n",
    "\n",
    "FILTER = [\"$$\", \"===\", \".\", \",\", \"'\", \"`\", \"{\", \"}\", \"(\", \")\", \"--\"]\n",
    "with open(\"interest-original.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "  for line in f:\n",
    "    sentence = []\n",
    "    for word in line.strip().split():\n",
    "      if word.strip() == \"\":\n",
    "        continue\n",
    "\n",
    "      if any([word.startswith(f) for f in FILTER]):\n",
    "        continue\n",
    "\n",
    "      # Le dataset est déjà tokenisé avec les tokens séparés par des espaces\n",
    "      sentence.append(word)\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "      sentences.append(sentence)\n",
    "\n",
    "print(\"Il y a {} phrases.\\nEn voici 3 au hasard :\".format(len(sentences)))\n",
    "for i in range(3):\n",
    "  print(f\"{i + 1}: {sentences[randrange(len(sentences))]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2368 phrases.\n",
      "En voici 3 au hasard :\n",
      "1: ['lower', 'u.s.', 'interest_6', 'rates', 'would', 'help', 'restrain', 'the', 'dollar']\n",
      "2: ['geoffrey', 'kalmus', 'counsel', 'to', 'the', 'official', 'creditors', 'committee', 'said', 'that', 'under', 'the', 'united', 'illuminating', 'plan', 'unsecured', 'creditors', 'would', 'be', 'paid', 'in', 'full', 'credits', 'and', 'interest_6', 'of', 'about', '$', '855', 'million', 'accrued', 'before', 'ps', 'of', 'new', 'hampshire', 'jan.', '1988', 'filing', 'for', 'bankruptcy', 'court', 'protection']\n",
      "3: ['interest_6', 'payments', 'on', 'the', 'bonds', 'will', 'be', 'payable', 'semiannually']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithme de Lesk simplifié\n",
    "\n",
    "**2a.** Définissez une fonction `wsd_lesk(senses, sentence)` qui prend deux arguments : une liste de listes de mots-clés (comme `senses1` et `senses2` ci-dessus) et une phrase avec une occurrence annotée de *interest* ou *interests*, et qui retourne l'index du sens le plus probable (entre 1 et 6) selon l'algorithme de Lesk.  Cet algorithme choisit le sens qui a le maximum de mots en commun avec le contexte de *interest*.  Vous pouvez choisir vous-mêmes la taille de ce voisinage (`window_size`).  En cas d'égalité entre deux sens, tirer la réponse au sort."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.748661Z",
     "start_time": "2025-05-22T12:28:27.746006Z"
    }
   },
   "source": [
    "def wsd_lesk(senses, sentence, words=(\"interest\", \"interests\"), window_size=8):\n",
    "  \"\"\"\n",
    "  Choisit le sens d'un mot donné selon l'algorithme de Lesk simplifié.\n",
    "  :param words: le/les mots d'intérêt (e.g. interest ou interests)\n",
    "  :param senses: liste de listes de mots-clés par sens\n",
    "  :param sentence: phrase avec une occurrence annotée de interest ou interests\n",
    "  :param window_size: taille de la fenêtre autour du mot d'intérêt\n",
    "  :return: numéro du sens le plus probable (1-6)\n",
    "  \"\"\"\n",
    "  word_index = [i for i, w in enumerate(sentence) if any([w.startswith(tw) for tw in words])][0]\n",
    "\n",
    "  best_sense = 0\n",
    "  max_overlap = 0\n",
    "  context = sentence[max(0, word_index - window_size):min(len(sentence), word_index + window_size + 1)]\n",
    "\n",
    "  # pick indices at random in case of a tie, to avoid bias on the first most common sense\n",
    "  sense_indices = list(range(len(senses)))\n",
    "  shuffle(sense_indices)\n",
    "  for i in sense_indices:\n",
    "    signature = set(senses[i])\n",
    "    overlap = len(signature.intersection(context))\n",
    "    if overlap > max_overlap:\n",
    "      max_overlap = overlap\n",
    "      best_sense = i\n",
    "\n",
    "  return 1 + best_sense"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b.** Définissez maintenant une fonction `evaluate_wsd(fct_name, senses, sentences)` qui prend en paramètre le nom de la méthode de similarité (pour commencer : `wsd_lesk`) ainsi que la liste des mots-clés par sens, et la liste de phrases, et qui retourne le score de la méthode de similarité.  Ce score sera tout simplement le pourcentage de réponses correctes (sens trouvé identique au sens annoté)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.792058Z",
     "start_time": "2025-05-22T12:28:27.788683Z"
    }
   },
   "source": [
    "def evaluate_wsd(fct_name, senses, sentences, window_size=8):\n",
    "  \"\"\"\n",
    "  Évalue la méthode de désambiguïsation lexicale.\n",
    "  :param fct_name: nom de la fonction de désambiguïsation lexicale\n",
    "  :param senses: liste de listes de mots-clés par sens\n",
    "  :param sentences: liste de phrases avec occurrences annotées\n",
    "  :return: score de la méthode de désambiguïsation lexicale\n",
    "  \"\"\"\n",
    "  correct = 0\n",
    "  for sentence in sentences:\n",
    "    for i, word in enumerate(sentence):\n",
    "      if word.startswith(\"interest_\") or word.startswith(\"interests_\"):\n",
    "        reference_score = int(word.split(\"_\")[1])\n",
    "        predicted_score = fct_name(senses, sentence, window_size=window_size)\n",
    "        if reference_score == predicted_score:\n",
    "          correct += 1\n",
    "\n",
    "  return correct / len(sentences)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** En fixant au mieux la taille de la fenêtre autour de *interest*, quel est le meilleur score de la méthode de Lesk simplifiée ?  Quelle liste de sens conduit à de meilleurs scores, `senses1` ou `senses2` ?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:27.861081Z",
     "start_time": "2025-05-22T12:28:27.858279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_evaluations(fct, senses):\n",
    "  \"\"\"\n",
    "  Évalue la méthode de désambiguïsation lexicale avec différentes tailles de fenêtres.\n",
    "  :param fct: la fonction à évaluer\n",
    "  :param senses: liste de listes de mots-clés par sens\n",
    "  :return: score maximal observé\n",
    "  \"\"\"\n",
    "  for i in range(20):\n",
    "    scores = []\n",
    "    for j in range(5):\n",
    "      score = evaluate_wsd(fct, senses, sentences, window_size=i + 1)\n",
    "      scores.append(score)\n",
    "    print(f\"Window size {i + 1}: {(sum(scores) / len(scores)) * 100:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:28:34.335959Z",
     "start_time": "2025-05-22T12:28:27.919120Z"
    }
   },
   "source": [
    "print(f\"Évaluation du score avec senses1 :\")\n",
    "run_evaluations(wsd_lesk, senses1)\n",
    "\n",
    "print(f\"\\nÉvaluation du score avec senses2 :\")\n",
    "run_evaluations(wsd_lesk, senses2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du score avec senses1 :\n",
      "Window size 1: 15.67%\n",
      "Window size 2: 16.60%\n",
      "Window size 3: 16.93%\n",
      "Window size 4: 17.41%\n",
      "Window size 5: 18.16%\n",
      "Window size 6: 18.19%\n",
      "Window size 7: 18.64%\n",
      "Window size 8: 19.01%\n",
      "Window size 9: 19.31%\n",
      "Window size 10: 19.43%\n",
      "Window size 11: 19.38%\n",
      "Window size 12: 19.65%\n",
      "Window size 13: 19.73%\n",
      "Window size 14: 19.94%\n",
      "Window size 15: 19.99%\n",
      "Window size 16: 20.04%\n",
      "Window size 17: 20.02%\n",
      "Window size 18: 20.14%\n",
      "Window size 19: 20.46%\n",
      "Window size 20: 20.48%\n",
      "\n",
      "Évaluation du score avec senses2 :\n",
      "Window size 1: 16.22%\n",
      "Window size 2: 17.61%\n",
      "Window size 3: 18.50%\n",
      "Window size 4: 19.10%\n",
      "Window size 5: 20.28%\n",
      "Window size 6: 20.84%\n",
      "Window size 7: 21.35%\n",
      "Window size 8: 21.59%\n",
      "Window size 9: 22.10%\n",
      "Window size 10: 22.38%\n",
      "Window size 11: 22.47%\n",
      "Window size 12: 22.80%\n",
      "Window size 13: 23.03%\n",
      "Window size 14: 23.13%\n",
      "Window size 15: 23.23%\n",
      "Window size 16: 23.23%\n",
      "Window size 17: 23.31%\n",
      "Window size 18: 23.34%\n",
      "Window size 19: 23.70%\n",
      "Window size 20: 23.75%\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Naturellement, une taille de fenêtre plus grande permet de trouver plus de mots en communs. Pour une taille de fenêtre trop petite, le score revient essentiellement à la probabilité de tomber sur le bon sens (1/6).\n",
    ">\n",
    "> Les scores de la liste `senses2` sont meilleurs ce qui est logique car cette liste contient un plus grand ensemble de mots-clés pour chaque sens.\n",
    "> Une des grandes critiques de l'algorithme de Lesk que nous pouvons observer ici est qu'il est très dépendant à la liste de mots-clés du sens du dictionnaire, et ceux-cis sont souvent très courts et ne contiennent pas un vocabulaire très riche.\n",
    ">\n",
    "> Les meilleurs scores sont autour de 20% +/- 1% pour `senses1` et 23% +/- 1% pour `senses2`. Une taille de fenêtre entre 12 et 16 semble offrir un contexte déjà suffisant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Utilisation de word2vec pour la similarité contexte vs. synset\n",
    "\n",
    "**3a.** En réutilisant une partie du code de `wsd_lesk`, veuillez maintenant définir une fonction `wsd_word2vec(senses, sentence)` qui choisit le sens en utilisant la similarité **word2vec** étudiée dans le labo précédent. \n",
    "* Vous pouvez chercher dans la [documentation des KeyedVectors](https://radimrehurek.com/gensim/models/keyedvectors.html) comment calculer directement la similarité entre deux listes de mots.\n",
    "* Comme `wsd_lesk`, la nouvelle fonction `wsd_word2vec` prend en argument une liste de listes de mots-clés par sens (comme `senses1` et `senses2` ci-dessus), et une phrase avec une occurrence annotée de *interest* ou *interests*.\n",
    "* La fonction retourne le numéro du sens le plus probable selon la similarité word2vec entre les mots du sens et ceux du voisinage de *interest*.  En cas d'égalité, tirer le sens au sort.\n",
    "* Vous pouvez régler la taille du voisinage (`window_size`) par l'expérimentation.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:29:04.460627Z",
     "start_time": "2025-05-22T12:28:34.349292Z"
    }
   },
   "source": [
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import downloader\n",
    "\n",
    "path_to_model = downloader.load(\"word2vec-google-news-300\", return_path=True)\n",
    "wv_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_model, binary=True)  # C bin format"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:29:04.497068Z",
     "start_time": "2025-05-22T12:29:04.493752Z"
    }
   },
   "source": [
    "def wsd_word2vec(senses, sentence, words=(\"interest\", \"interests\"), window_size=8):\n",
    "  \"\"\"\n",
    "  Choisit le sens d'un mot donné en comparant les scores de similarités du cosinus word2vec.\n",
    "  :param words: le/les mots d'intérêt (e.g. interest ou interests)\n",
    "  :param senses: liste de listes de mots-clés par sens\n",
    "  :param sentence: phrase avec une occurrence annotée de interest ou interests\n",
    "  :param window_size: taille de la fenêtre autour du mot d'intérêt\n",
    "  :return: numéro du sens le plus probable (1-6)\n",
    "  \"\"\"\n",
    "  word_index = [i for i, w in enumerate(sentence) if any([w.startswith(tw) for tw in words])][0]\n",
    "\n",
    "  best_sense = 0\n",
    "  max_similarity = 0\n",
    "  context = sentence[max(0, word_index - window_size):min(len(sentence), word_index + window_size + 1)]\n",
    "\n",
    "  # pick indices at random in case of a tie, to avoid bias on the first most common sense\n",
    "  sense_indices = list(range(len(senses)))\n",
    "  shuffle(sense_indices)\n",
    "  for i in sense_indices:\n",
    "    signature = set(senses[i])\n",
    "    similarity = wv_model.n_similarity(context, signature)\n",
    "    if similarity > max_similarity:\n",
    "      max_similarity = similarity\n",
    "      best_sense = i\n",
    "\n",
    "  return 1 + best_sense"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Appliquez maintenant la même méthode `evaluate_wsd` avec la fonction `wsd_word2vec` (en cherchant une bonne valeur de la taille de la fenêtre) et affichez le score de la similarité word2vec.  Comment se compare-t-il avec le score précédent (Lesk) ?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:11.296513Z",
     "start_time": "2025-05-22T12:29:04.556380Z"
    }
   },
   "source": [
    "print(f\"Évaluation du score avec senses1 :\")\n",
    "run_evaluations(wsd_word2vec, senses1)\n",
    "\n",
    "print(f\"\\nÉvaluation du score avec senses2 :\")\n",
    "run_evaluations(wsd_word2vec, senses2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation du score avec senses1 :\n",
      "Window size 1: 32.26%\n",
      "Window size 2: 35.85%\n",
      "Window size 3: 39.19%\n",
      "Window size 4: 41.39%\n",
      "Window size 5: 42.91%\n",
      "Window size 6: 43.71%\n",
      "Window size 7: 43.37%\n",
      "Window size 8: 43.75%\n",
      "Window size 9: 43.29%\n",
      "Window size 10: 43.71%\n",
      "Window size 11: 44.13%\n",
      "Window size 12: 44.30%\n",
      "Window size 13: 44.51%\n",
      "Window size 14: 43.96%\n",
      "Window size 15: 43.96%\n",
      "Window size 16: 43.41%\n",
      "Window size 17: 43.50%\n",
      "Window size 18: 43.24%\n",
      "Window size 19: 42.91%\n",
      "Window size 20: 43.20%\n",
      "\n",
      "Évaluation du score avec senses2 :\n",
      "Window size 1: 56.63%\n",
      "Window size 2: 59.54%\n",
      "Window size 3: 60.52%\n",
      "Window size 4: 61.49%\n",
      "Window size 5: 62.67%\n",
      "Window size 6: 60.73%\n",
      "Window size 7: 60.56%\n",
      "Window size 8: 60.26%\n",
      "Window size 9: 60.68%\n",
      "Window size 10: 60.64%\n",
      "Window size 11: 59.84%\n",
      "Window size 12: 59.63%\n",
      "Window size 13: 59.33%\n",
      "Window size 14: 59.21%\n",
      "Window size 15: 58.15%\n",
      "Window size 16: 58.23%\n",
      "Window size 17: 58.45%\n",
      "Window size 18: 58.23%\n",
      "Window size 19: 58.32%\n",
      "Window size 20: 58.19%\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Après évaluation, on peut déterminer que la taile de fenêtre qui offre un bon compromis entre performance est de nouveau entre 4 et 8.\n",
    ">\n",
    "> Dans cette fourchette, le score avec `senses1` est de 42% +/- 2% et avec `senses2` de 62% +/- 1%.\n",
    "> On peut donc conclure que la méthode de similarité du cosinus en utilisant word2vec est déjà bien plus performante que l'algorithme de Lesk simplifié. On constate toutefois comme précédemment l'importance des mots-clés définis pour chaque sens, un extrait avec un vocabulaire plus riche offre de meilleures performances et la différence est plus significative (20% avec word2vec contre 3% pour Lesk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification supervisée avec des traits lexicaux\n",
    "Vous entraînerez maintenant des classifieurs pour prédire le sens d'une occurrence dans une phrase.  Le premier but sera de transformer chaque phrase en un ensemble d'attributs pour formater les données en vue des expériences de classification.\n",
    "\n",
    "Veuillez utiliser le classifieur `NaiveBayesClassifier` fourni par NLTK.  Le mode d'emploi se trouve dans le [Chapitre 6, sections 1.1-1.3](https://www.nltk.org/book/ch06.html) du livre NLTK.  Consultez-le attentivement pour trouver comment formater les données.  De plus, il faudra séparer les données en sous-ensembles d'entraînement et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vous propose de nommer les attributs `word-k`, ..., `word-2`, `word-1`, `word+1`, `word+2`, ..., `word+k` (fenêtre de taille `2*k` autour de *interest*).  Leurs valeurs sont les mots observés aux emplacements respectifs, ou `NONE` si la position dépasse l'étendue de la phrase.  Vous ajouterez un attribut nommé `word0` qui est l'occurrence du mot *interest* au singulier ou au pluriel.  \n",
    "\n",
    "Pour chaque occurrence de *interest*, vous devrez donc créer la représentation suivante (où `6` est le numéro du sens, essentiel pour l'entraînement, mais à cacher lors de l'évaluation) :\n",
    "```\n",
    "[{'word-1': 'in', 'word+1': 'rates', 'word-2': 'declines', 'word+2': 'NONE', 'word0': 'interest'}, 6]\n",
    "```\n",
    "\n",
    "**4a.** En partant de la liste des phrases appelée `sentences` préparée plus haut, veuillez générer la liste avec toutes les représentation, appelée `items_with_features`.  Vous pouvez vous aider du livre NLTK."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:11.420608Z",
     "start_time": "2025-05-22T12:33:11.365347Z"
    }
   },
   "source": [
    "window_size = 2\n",
    "\n",
    "items_with_features = []\n",
    "for sentence in sentences:\n",
    "  for i, word in enumerate(sentence):\n",
    "    if word.startswith(\"interest_\") or word.startswith(\"interests_\"):\n",
    "      [word, sense] = word.split(\"_\")\n",
    "      result = dict()\n",
    "      for j in range(1, window_size + 1):\n",
    "        result[f\"word-{j}\"] = sentence[i - j] if i - j >= 0 else \"NONE\"\n",
    "        result[f\"word+{j}\"] = sentence[i + j] if i + j < len(sentence) else \"NONE\"\n",
    "\n",
    "      result[\"word0\"] = word\n",
    "      items_with_features.append([result, int(sense)])\n",
    "\n",
    "print(len(items_with_features))\n",
    "print(items_with_features[151:154])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368\n",
      "[[{'word-1': 'investor', 'word+1': 'in', 'word-2': 'NONE', 'word+2': 'stock', 'word0': 'interest'}, 1], [{'word-1': 'western', 'word+1': 'to', 'word-2': 'the', 'word+2': 'see', 'word0': 'interest'}, 4], [{'word-1': 'of', 'word+1': 'because', 'word-2': 'expression', 'word+2': 'under', 'word0': 'interest'}, 1]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.** Veuillez séparer les données aléatoirement en 80% pour l'entraînement et 20%  pour l'évaluation.  Veuillez faire une division stratifiée : les deux sous-ensembles doivent contenir les mêmes proportions de sens que l'ensemble de départ.  Ils seront appelés `iwf_train` et `iwf_test`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:11.477007Z",
     "start_time": "2025-05-22T12:33:11.472730Z"
    }
   },
   "source": [
    "train_ratio = 0.8\n",
    "\n",
    "iwf_train = []\n",
    "iwf_test = []\n",
    "\n",
    "for sense in range(1, len(senses1) + 1):\n",
    "  sense_items = [i for i in items_with_features if i[1] == sense]\n",
    "  shuffle(sense_items)\n",
    "\n",
    "  cutoff = floor(len(sense_items) * train_ratio)\n",
    "  iwf_train.extend(sense_items[:cutoff])\n",
    "  iwf_test.extend(sense_items[cutoff:])\n",
    "\n",
    "print(len(iwf_train), ' ', len(iwf_test))\n",
    "print(iwf_test[:2], iwf_test[-2:])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891   477\n",
      "[[{'word-1': 'unwelcome', 'word+1': 'in', 'word-2': 'recent', 'word+2': 'its', 'word0': 'interest'}, 1], [{'word-1': 'congressional', 'word+1': 'in', 'word-2': 'exploit', 'word+2': 'bolar', 'word0': 'interest'}, 1]] [[{'word-1': 'NONE', 'word+1': 'on', 'word-2': 'NONE', 'word+2': 'bonds', 'word0': 'interest'}, 6], [{'word-1': 'lower', 'word+1': 'costs', 'word-2': 'to', 'word+2': 'significantly', 'word0': 'interest'}, 6]]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez créer une instance de `NaiveBayesClassifier`, l'entraîner sur `iwf_train` et la tester sur `iwf_test` (voir la documentation NLTK).  En expérimentant avec différentes largeurs de fenêtres, quel est le meilleur score que vous obtenez (avec la fonction `accuracy` de NLTK) sur l'ensemble de test ?  Comment se compare-t-il avec les précédents ?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:11.558898Z",
     "start_time": "2025-05-22T12:33:11.535562Z"
    }
   },
   "source": [
    "from nltk.classify import naivebayes\n",
    "\n",
    "classifier = naivebayes.NaiveBayesClassifier.train(iwf_train)\n",
    "print(f\"Précision: {nltk.classify.accuracy(classifier, iwf_test) * 100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision: 89.94%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> En conservant une la taille de fenêtre de 2 telle que proposée, nous obtenons le meilleur score de 88% +/- 3% (en fonction de la séparation aléatoire de l'ensemble d'entrainement).\n",
    ">\n",
    "> Des fenêtres plus larges n'offrent pas nécessairement de meilleures performances, même parfois dégrade légèrement le score (avec une taille de 12, nous obtenons 85% +/- 3%). On peut supposer que le modèle aura tendance à faire de l'overfitting si trop d'informations sont fournies, ou alors que trop souvent les mots fournis sont `NONE` car la phrase évaluée est trop petite pour fournir autant d'informations.\n",
    "> On peut donc conclure que la taille de 2 offre déjà de très bonnes performances, notamment par rapport aux méthodes précédentes.\n",
    ">\n",
    "> Ce score est bien plus élevé que celui de l'algorithme de Lesk (21% +/- 1%) et de la similarité word2vec (62% +/- 1%).  Il est donc évident que la classification supervisée est bien plus performante que les deux autres méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** En utilisant la fonction `show_most_informative_features()`, veuillez afficher les attributs les plus informatifs et commenter le résultat."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:11.598932Z",
     "start_time": "2025-05-22T12:33:11.590489Z"
    }
   },
   "source": "classifier.show_most_informative_features(16)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   word0 = 'interests'         3 : 1      =     90.5 : 1.0\n",
      "                  word+1 = 'in'                5 : 6      =     88.1 : 1.0\n",
      "                  word-1 = 'other'             3 : 6      =     36.6 : 1.0\n",
      "                  word+1 = 'of'                4 : 6      =     29.0 : 1.0\n",
      "                  word+2 = 'and'               6 : 5      =     24.9 : 1.0\n",
      "                  word+2 = 'on'                6 : 5      =     18.7 : 1.0\n",
      "                  word-1 = 'in'                6 : 5      =     17.5 : 1.0\n",
      "                  word-1 = 'own'               4 : 6      =     16.6 : 1.0\n",
      "                  word-2 = 'NONE'              6 : 4      =     14.8 : 1.0\n",
      "                  word+1 = 'was'               1 : 6      =     14.2 : 1.0\n",
      "                  word-2 = 'have'              1 : 6      =     12.5 : 1.0\n",
      "                  word+2 = 'to'                6 : 1      =     12.5 : 1.0\n",
      "                  word+1 = 'are'               3 : 6      =     12.2 : 1.0\n",
      "                  word-2 = 'is'                1 : 6      =     10.8 : 1.0\n",
      "                  word-2 = 'and'               5 : 3      =     10.6 : 1.0\n",
      "                  word-2 = 'other'             3 : 6      =     10.5 : 1.0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> On observe les traits les plus informatifs suivants:\n",
    "> - le mot `interest` au pluriel est très informatif, ce qui est logique car une bonne partie des sens ne sont pas des noms comptables et certains sens sont souvent uniquement utilisés au pluriel (ici, le modèle s'en sert pour séparer le sens 1 (un intérêt pour une chose) du sens 3 (les intérêts pour une activité)).\n",
    "> - ce que l'on considère comme des stop-words (`in`, `of`) sont quand même utilisés comme traits informatifs s'ils sont positionnés directement après le mot. Ce n'est pas surprenant car, par exemple, `in` est souvent utilisé dans le sens 1 (intérêt pour une personne ou quelque chose), le modèle s'en sert principalement pour distinguer le sens 5 (intérêts pour une entreprise) du sens 6 (argent reçu pour l'utilisation de l'argent).\n",
    "> - enfin, la présence du mot `other` précédant le mot est aussi considéré informatif pour distinguer du sens 3 su sens 6, ce qui est encore une fois plutôt logique (on parle souvent d'autres intérêts pour finaliser les préfèrences d'une personne)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e.** On souhaite également obtenir les scores pour chaque sens.  Pour ce faire, il faut demander les prédictions une par une au classifieur (voir le [livre NLTK](https://www.nltk.org/book/ch06.html)), et comptabiliser les prédictions correctes pour chaque sens.  Vous pouvez vous inspirer de `evaluate_wsd`, et écrire une fonction `evaluate_wsd_supervised(classifier, items_with_features)`, que vous appliquerez aux donnés `iwf_test`.  Veuillez afficher ces scores."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:11.673595Z",
     "start_time": "2025-05-22T12:33:11.645702Z"
    }
   },
   "source": [
    "def evaluate_wsd_supervised(classifier, items_with_features):\n",
    "  correct = [0] * len(senses1)\n",
    "  total = [0] * len(senses1)\n",
    "\n",
    "  for item in items_with_features:\n",
    "    features, reference_score = item\n",
    "    predicted_score = classifier.classify(features)\n",
    "    if reference_score == predicted_score:\n",
    "      correct[reference_score - 1] += 1\n",
    "    total[reference_score - 1] += 1\n",
    "\n",
    "  return [(i + 1, correct[i], total[i], (correct[i] / total[i]) * 100) for i in range(len(correct))]\n",
    "\n",
    "scores = evaluate_wsd_supervised(classifier, iwf_test)\n",
    "df = pd.DataFrame(columns=[\"Sens\", \"Correct\", \"Total\", \"Score\"])\n",
    "df.set_index(\"Sens\", inplace=True)\n",
    "for i, score in enumerate(scores):\n",
    "  df.loc[i + 1] = [score[1], score[2], score[3]]\n",
    "\n",
    "df[\"Score\"] = df[\"Score\"].apply(lambda x: f\"{x:.2f}%\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Correct  Total   Score\n",
       "Sens                        \n",
       "1        60.0   73.0  82.19%\n",
       "2         0.0    3.0   0.00%\n",
       "3         9.0   14.0  64.29%\n",
       "4        32.0   36.0  88.89%\n",
       "5        88.0  100.0  88.00%\n",
       "6       240.0  251.0  95.62%"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "      <th>Total</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sens</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>82.19%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>64.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>88.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>240.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>95.62%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "Veuillez recopier ci-dessous, en guise de conclusion, les scores des trois expériences réalisées, pour pouvoir les comparer d'un coup d'oeil.  Quel est le meilleur score obtenu?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T12:33:14.605346Z",
     "start_time": "2025-05-22T12:33:11.736444Z"
    }
   },
   "source": [
    "df = pd.DataFrame(columns=[\"Method\", \"Score (senses1)\", \"Score (senses2)\"])\n",
    "df.loc[0] = [\"Lesk simplifié\", evaluate_wsd(wsd_lesk, senses1, sentences, 12), evaluate_wsd(wsd_lesk, senses2, sentences, 12)]\n",
    "df.loc[1] = [\"word2Vec\", evaluate_wsd(wsd_word2vec, senses1, sentences, 10), evaluate_wsd(wsd_word2vec, senses2, sentences, 10)]\n",
    "df.loc[2] = [\"Classification supervisée\", nltk.classify.accuracy(classifier, iwf_test), \"N/A\"]\n",
    "\n",
    "for col in df.columns[1:]:\n",
    "  df[col] = df[col].apply(lambda x: f\"{x * 100:.2f}%\" if isinstance(x, float) else x)\n",
    "\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      Method Score (senses1) Score (senses2)\n",
       "0             Lesk simplifié          19.59%          22.89%\n",
       "1                   word2Vec          43.71%          60.64%\n",
       "2  Classification supervisée          89.94%             N/A"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Score (senses1)</th>\n",
       "      <th>Score (senses2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lesk simplifié</td>\n",
       "      <td>19.59%</td>\n",
       "      <td>22.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>word2Vec</td>\n",
       "      <td>43.71%</td>\n",
       "      <td>60.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Classification supervisée</td>\n",
       "      <td>89.94%</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "> La classification supervisée obtient le meilleur score. Dans nos itérations multiples, nous avons pu observer un score maximal de 91.19%."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin du laboratoire\n",
    "\n",
    "Merci de nettoyer votre feuille, sauvegarder le résultat, et soumettre le *notebook* sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cours_tal",
   "language": "python",
   "name": "cours_tal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
